GENERAL:
  task: train  # train, test
  manual_seed: 234
  model_dir: model/pointgroup/pointgroup.py
  dataset_dir: data/planteye_inst.py

DATA:
  data_root: dataset
  dataset: planteye
  filename_suffix: _inst_nostuff.pth

  classes: 3
  ignore_label: -100

  input_channel: 3
  scale: 33   # voxel_size = 1 / scale, scale 50(2cm)
  batch_size: 1
  full_scale: [128, 512]
  max_npoint: 250000
  mode: 4 # 4=mean

STRUCTURE:
  model_name: pointgroup
  m: 16 # 16 or 32
  block_residual: True
  block_reps: 2
  use_coords: True

TRAIN:
  max_iter: 50001
  train_workers: 0 # data loader workers
  optim: Adam # Adam or SGD
  lr: 0.001
  step_epoch: 384
  multiplier: 0.5
  momentum: 0.9
  weight_decay: 0.0000000001
  save_freq: 10000  # also eval_freq
  loss_weight: [1.0, 1.0, 1.0, 1.0] # semantic_loss, offset_norm_loss, offset_dir_loss, score_loss

  fg_thresh: 0.75
  bg_thresh: 0.25

  #score_scale: 50 # the minimal voxel size is 2cm
  score_scale: 33 #voxel size is 3cm
  score_fullscale: 14
  score_mode: 4 # mean

  pretrain_path:
  pretrain_module: []
  fix_module: []

GROUP:
  ### point grouping
  #cluster_radius: 0.02
  #cluster_meanActive: 50
  #cluster_shift_meanActive: 300
  #cluster_npoint_thre: 10
  prepare_epochs: 100
  ## preprare epochs should be greater than test epochs to find nclusters
  ## Best parameters after Bayseian search
  cluster_meanActive: 37
  cluster_npoint_thre: 21
  cluster_radius: 0.04678167676571324
  cluster_shift_meanActive: 245
TEST:
  split: val
  test_epoch: 250
  test_workers: 0
  test_seed: 567

  TEST_NMS_THRESH: 0.25
  TEST_SCORE_THRESH: 0.6
  TEST_NPOINT_THRESH: 5
  
  eval: True
  save_semantic: False
  save_pt_offsets: False
  save_instance: False
