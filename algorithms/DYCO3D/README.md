## Based on DyCo3d: Robust Instance Segmentation of 3D Point Clouds through Dynamic Convolution (CVPR 2021)
### Local Training and Evaluation
### Dataset prepration
* Run **write_dyco3d_input.py** (requires open3d package) with appropriate input paths of ply input point clouds and .zlib annotation file generated from Sagemaker point cloud labelling.
Output will be preprocessed ply files with labels written in text file in form (Nx1) where N are the number of point clouds in downsampled ply file.
Change this preprocessing step according to your needs (specify custom voxel size, scaling, height based filtering e.tc)
* Run **dataset/planteye/prepare_data_inst_planteye.py** to generate combine labels and ply in uniform .pth format for training DyCo3D

### Local Training
* Modify config in **config/dycodyco3d_planteye.yaml** to desired dataset, iterations, learning rate, model checkpoint iterations, Evaluation epochs e.t.c
* Run train.py to run the training

### Inference
* Use the checkpoint created by training and use in test.py  to test the dataset
* (Optional) Run **find_best_test_params.py** to perform grid search on best minimum number of points, score threshold and nms threshold to give the best mAP
* Visualize the results running  **visualize_dyco3d_out.py** (requires open3d package) by providing approriate paths of the mask generated by test step.

### Sagemaker Training and Hyperparameter Tuning
* Copy all the files in directory in Sagmeaker
* Run docker_build.ipynb to build docker image and push to Amazon ECR for training
* Run train_sagemaker.ipynb to train the Dyco3D for any particular hyperparameter or perform hyperparameter search
* Run HPO.ipynb for see the best performing model 
