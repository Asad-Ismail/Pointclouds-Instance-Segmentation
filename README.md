# Pointclouds (Custom dataset) Annotation and Instance Segmentation 

Provides End to End pipeline for Annotation and Instance Segmentation of Point Clouds

## Annotation:
Pointcloud annotation performed using Amazon Sagmeaker 3D labelling tool

# Local Training and Evaluation
## Data prepration
* Run **write_dyco3d_input.py** (requires open3d package) with appropriate input paths of ply input point clouds and .zlib annotation file generated from Sagemaker point cloud labelling.
Output will be preprocessed ply files with labels written in text file in form (Nx1) where N are the number of point clouds in downsampled ply file.
Change this preprocessing step according to your needs (specify custom voxel size, scaling, height based filtering e.tc)
* Run **dataset/planteye/prepare_data_inst_planteye.py** to generate combine labels and ply in unifrm .pth format for training DyCo3D

### Instance Segmentation
* Based on https://github.com/aim-uofa/DyCo3D DyCo3D DyCo3d: Robust Instance Segmentation of 3D Point Clouds through Dynamic Convolution (CVPR 2021)
  and https://github.com/dvlab-research/PointGroup PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation (CVPR2020)
* Modify config in **config/dycodyco3d_planteye.yaml** to desired dataset, iterations, learning rate, model checkpoint iterations, Evaluation epochs e.t.c
* Run train.py to run the training
* Use the checkpoint created by training and use in test.py  to test the dataset
* (Optional) Run **find_best_test_params.py** to perform grid search on best minimum number of points, score threshold and nms threshold to give the best mAP
* Visualize the results running  **visualize_dyco3d_out.py** (requires open3d package) by providing approriate paths of the mask generated by test step.
* Example Input Point cloud, Labels and Prediction is shown below

  <p align="center">
    <img src="images/image.png" alt="pruning" />
  </p>
   <p align="center">


# Sagemaker Training and Hyperparameter Tuning
* Use Dockerfile to build Dyco3D image and push to ECR for training the model in Sagemaker 

