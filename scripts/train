#!/usr/bin/env python

from __future__ import print_function
import tensorflow as tf
import tensorflow.keras as K
import argparse
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.optimizers import RMSprop, Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
from datetime import datetime
import numpy as np
import pathlib
import time
from Model import Model
from utils import show_images
import sys
import traceback
import json


# These are the paths to where SageMaker mounts interesting things in your container.
prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')
data_path  = os.path.join(prefix, 'input/config/inputdataconfig.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name_train='training'
training_path = os.path.join(input_path, channel_name_train)
channel_name_val='validation'
validation_path = os.path.join(input_path, channel_name_val)
logdir = output_path+"/logs/scalars/" + datetime.now().strftime("%Y%m%d-%H%M%S")

def train_model(model,train_data,test_data,epochs=1,steps_per_epoch=10,validation_steps=1):
    metric = 'val_accuracy'
    checkpoint= ModelCheckpoint(model_path+"/weights_best.hdf5", monitor=metric, verbose=1,save_best_only=True, mode='max')
    tensorboard_callback = K.callbacks.TensorBoard(log_dir=logdir)
    callbacks_list = [checkpoint,tensorboard_callback]
    history = model.fit(train_data,epochs=epochs,validation_data=test_data,steps_per_epoch=steps_per_epoch,validation_steps=validation_steps,callbacks=[callbacks_list])
    return history


# The function to execute the training.
def train():
    print('Starting the training.')
    try:
        # Read in any hyperparameters that the user passed with the training job
        with open(param_path, 'r') as tc:
            hyperParams = json.load(tc)            
        print("Hyper parameters: " + str(hyperParams))
        
        lr=float(hyperParams.get('lr', '0.1'))
        batch_size=int(hyperParams.get('batch_size', '128'))
        epochs=int(hyperParams.get('epochs', '10'))
        gpu_count=int(hyperParams.get('gpu_count', '1'))
        
        with open(data_path, 'r') as params:
            inputParams = json.load(params)
        print("Input parameters: " + str(inputParams))

        # Asserting that gpu and cuda is available for trianing
        assert tf.test.is_gpu_available(), f"The gpu is not available something is wrong"
        assert tf.test.is_built_with_cuda(), f"The cuda is not available something is wrong"
        
        model=Model()
        print(model.summary())
        model.compile(optimizer=Adam(lr),loss="categorical_crossentropy",metrics=["accuracy"])
        train_datagen = ImageDataGenerator(rescale=1/255.0,
                                    rotation_range=20,
                                    horizontal_flip=True,
                                    width_shift_range=0.2,
                                    height_shift_range=0.2,
                                    shear_range=0.3,
                                    zoom_range=0.5,
                                    vertical_flip=True
                                    )
        train_data=train_datagen.flow_from_directory(training_path,target_size=(100,100),batch_size=batch_size)
    	#show_images(train_data)
        test_datagen=ImageDataGenerator(rescale=1/255.0)
        test_data=test_datagen.flow_from_directory(validation_path,target_size=(100,100),batch_size=batch_size)
        his=train_model(model,train_data,test_data)
        print('Training complete!!!!')
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()
    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
